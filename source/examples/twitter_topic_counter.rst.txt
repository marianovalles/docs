.. index:: example, twitter, scala

.. contents::

Twitter Topic Counter
=====================

In this example, we describe how to write a simple real world streaming example in S4. 

We use everyone's favorite stream, Twitter (specifically, the `gardenhose <http://dev.twitter.com/pages/streaming_api_methods#statuses-sample>`_ stream), extract hash tags (those strings that start with #; we'll call them topics) from it, and generate the list of top 10 topics. 

Code for this example is at `https://github.com/s4/examples/tree/master/twittertopiccount_scala <https://github.com/s4/examples/tree/master/twittertopiccount_scala>`_

This example displays snippets in the Scala language, but the repository also has a `Java version <https://github.com/s4/examples/tree/master/twittertopiccount>`_. 

Application Design
------------------

.. image:: /_static/twitter_example_app.png

The Events
----------

The application writer creates a class for each type of event. In this case, we define a ``Status`` class (to represent status messages) and a ``Topic`` class (to represent topics extracted from the tweet). Additionally, we also define a ``User`` class, for use as a member of the ``Status`` class. (We can potentially have streams of User events as well, but we won't do that in this example)

.. code-block:: scala

  // Event: Status
  case class Status(
    @BeanProperty var id: Long,
    @BeanProperty var text: String,
    @BeanProperty var created_at: String,
    @BeanProperty var user: User
  ) {
    def this()= this(0L, null, null, null)
  }

  // Event: Topic
  case class Topic (
    @BeanProperty var topic: String,  
    @BeanProperty var count: Int
  ) {
    @BeanProperty var reportKey: String = _
    def this()= this(null, 0)
  }

  // Event: User
  case class User (
    @BeanProperty var id: Long, 
    @BeanProperty var name: String, 
    @BeanProperty var screen_name: String
  ) {
    def this()= this(0L, null, null)
  }


The Adapter
-----------

The adapter interfaces with the external world, in this case Twitter, and emits ``Status`` events onto a stream called ``RawStatus``

The Processors (PEs)
--------------------

This application involves 3 PEs: ``TopicExtractorPE``, ``TopicCountAndReportPE`` and ``TopNTopicPE``

**Figure**: Flow of events through PE's

.. image:: /_static/twitter_example_pe.png
  
TopicExtractorPE
^^^^^^^^^^^^^^^^

**Input**
  Stream: ``RawStatus``, Key: Any
**Output**
  Stream: ``TopicSeen``

``TopicExtractorPE`` listens to the ``RawStatus`` stream (generated by the adapter), any key, and creates one ``Topic`` event for each topic encountered in the text field of the status messages. It emits ``Topic`` events onto the ``TopicSeen`` stream. Each ``Topic`` event contains the extracted topic (as a string) and a count of 1.

**Configuration**

.. code-block:: xml

  <bean id="topicExtractorPE" class="com.yahoo.s4.example.twittertopiccount.TopicExtractorPE">
    <property name="id" value="topicSeenPE"/>
    <property name="keys">
      <list>
        <value>RawStatus *</value>
      </list>
    </property>
    <property name="dispatcher" ref="dispatcher"/>
    <property name="outputStreamName" value="TopicSeen"/>
  </bean>

**Notes**
  * Because ``TopicExtractorPE`` does not subscribe to any key (indicated by "*"), there is only one topic extract PE per S4 node.
  * ``TopicExtractorPE`` uses the dispatcher to emit events onto a stream. The dispatcher is called that because it dispatches an event to the appropriate node(s) based on the specified key.

**Implementation**

.. code-block:: scala

  class TopicExtractorPE extends AbstractPE {
    @BeanProperty var id: String = _ 
    @BeanProperty var dispatcher: Dispatcher = _ 
    @BeanProperty var outputStreamName: String = _ 

    def processEvent(status: Status): Unit= {    
      var text = status.text
      if (text == null) return
      hashtags(text).foreach { x => 
        dispatcher.dispatchEvent(outputStreamName, new Topic(x, 1))
      }
    }

    def hashtags(in: String): Array[String]= in.split(" ").filter(_.startsWith("#")).map(_.replaceAll("[^a-zA-Z0-9]", ""))

    def output(): Unit= {
    }
  }

**Notes**
  * In ``TopicExtractorPE``, the ``processEvent(status: Status)`` code implements the required processing on events of type ``Status``. The ``output()`` method does nothing. 

TopicCountAndReportPE
^^^^^^^^^^^^^^^^^^^^^

**Input**
  Stream: ``TopicSeen``, Key: ``topic``
**Output**
  Stream: ``AggregatedTopicSeen``

``TopicCountAndReportPE`` listens to the ``TopicSeen`` stream keyed on ``topic``, maintains a counter for the topic. Additionally, the PE occasionally checks if the counter is above a certain threshold, and if so, it emits an event of type ``Topic`` onto the stream ``AggregatedTopicSeen``. 

**Configuration**

.. code-block:: xml

  <bean id="topicCountAndReportPE" class="com.yahoo.s4.example.twittertopiccount.TopicCountAndReportPE">
    <property name="id" value="topicCountAndReportPE"/>
    <property name="keys">
      <list>
        <value>TopicSeen topic</value>
      </list>
    </property>
    <property name="threshold" value="4"/>
    <property name="outputFrequencyByTimeBoundary" value="5"/>
    <property name="dispatcher" ref="dispatcher"/>
    <property name="outputStreamName" value="AggregatedTopicSeen"/>
    <property name="ttl" value="36000"/>
  </bean>

**Notes**
  * ``TopicCountAndReportPE`` listens for events keyed on ``topic``. As a result, there will be one PE instance per topic. This allows a single instance of ``TopicCountAndReportPE`` to count occurrences of a single topic. S4 will distribute the PE instances across the nodes.
  * ``outputFrequencyByTimeBoundary`` value is set to 5. Therefore, each PE instance's ``output()`` method will be called on each 5 second boundary.

**Implementation**

.. code-block:: scala

  class TopicCountAndReportPE extends AbstractPE {
    @BeanProperty var id: String = _ 
    @BeanProperty var dispatcher: Dispatcher = _ 
    @BeanProperty var outputStreamName: String = _ 
    @BeanProperty var threshold: Int = _
    @BeanProperty var count: Int = _

    def processEvent(topic: Topic): Unit= {
      count += topic.count;
    }

    def output(): Unit= {
      if (count < threshold) return  
      var topic: Topic = new Topic(this.getKeyValue.get(0).toString, count)
      topic.reportKey = "1"
      dispatcher.dispatchEvent(outputStreamName, topic)
    }
  }

**Notes**
  * The ``output()`` method creates a ``Topic`` event with the current count.
  * The ``output()`` method gets the key on which this PE instance is keyed by calling ``this.getKeyValue()`` (a method provided by AbstractPE).
  * The ``output()`` method emits new ``Topic`` events on the output stream (configured to be ``AggregatedTopicSeen``).

TopNTopicPE
^^^^^^^^^^^

**Input**
  Stream: ``AggregatedTopicSeen``, Key: ``reportKey``
**Output**
  None

TopNTopicPE listens to the ``AggregatedTopicSeen`` stream for ``Topic`` events keyed on ``reportKey``. At regular intervals, it selects the top N topics by count, converts them into a JSON string and hands them off to a persister. The persister used in this example simply writes the resulting JSON to a file on disk. 

**Configuration**

.. code-block:: xml

  <bean id="top10TopicPE" class="com.yahoo.s4.example.twittertopiccount.TopNTopicPE">
    <property name="id" value="top10TopicPE"/>
    <property name="keys">
      <list>
        <value>AggregatedTopicSeen reportKey</value>
      </list>
    </property>
    <property name="entryCount" value="10"/>
    <property name="outputFrequencyByTimeBoundary" value="10"/>
    <property name="persister" ref="dtfPersister"/>
    <property name="persistTime" value="864000"/>
    <property name="persistKey" value="myapp:top10Topics"/>
    <property name="ttl" value="36000"/>
  </bean>

**Notes**
  * In this example, ``TopNTopicPE`` is configured to output the top 10 topics (``entryCount``) once every 10 seconds (``outputFrequencyByTimeBoundary``).
  * ``dtfPersister`` refers to an implementation of a Persister which simply writes output to a file on disk. 
  * Since the only possible value of ``reportKey`` is ``1`` (this value is set in ``TopicCountAndReportPE``), all events on the ``AggregatedTopicSeen`` stream end up in a single instance of ``TopNTopicPE``. This done because it is convenient to have all the top topics in a single PE to compute the top N. This works for this toy application, but in real applications, this is not a scalable approach. One alternative is to use a layer of intermediate 'reducers' to handle larger streams. 
  * This PE does not generate an output stream
  
**Implementation**

.. code-block:: scala

  class TopNTopicPE extends AbstractPE {
    @BeanProperty var id: String = _ 
    @BeanProperty var persistKey = "myapp:topNTopics"
    @BeanProperty var persister: Persister = _ 
    @BeanProperty var entryCount = 10
    @BeanProperty var persistTime = 0
    var topicMap = new ConcurrentHashMap[String, Int]

    def processEvent(topic: Topic): Unit= topicMap.put(topic.topic, topic.count)

    def output(): Unit= {

      // sort list of tuples by second value
      var sorted = topicMap.toList.sortBy(-_._2) 
      // limit to entryCount
      var tops = sorted.slice(0, min(entryCount, sorted.length))

      // use lift-json dsl to generate json
      val json = 
       ("topN" -> 
         tops.map { (x: (String, Int)) =>
  	      (("topic" -> x._1) ~ ("count" -> x._2))
         }
       )

      try {
        persister.set(persistKey, pretty(render(json)), persistTime)
      } catch {
        case e: Exception => Logger.getLogger("s4").error(e)     
      }
    }

  }


The Dispatcher
--------------

The Dispatcher is configured as follows: 

.. code-block:: xml

  <bean id="topicSeenPartitioner" class="com.yahoo.s4.dispatcher.partitioner.DefaultPartitioner">
    <property name="streamNames">
      <list>
        <value>TopicSeen</value>
      </list>
    </property>
    <property name="hashKey">
      <list>
        <value>topic</value>
      </list>
    </property>
    <property name="hasher" ref="hasher"/>
    <property name="debug" value="false"/>
  </bean>

  <bean id="aggregatedTopicSeenPartitioner" class="com.yahoo.s4.dispatcher.partitioner.DefaultPartitioner">
    <property name="streamNames">
      <list>
        <value>AggregatedTopicSeen</value>
      </list>
    </property>
    <property name="hashKey">
      <list>
        <value>reportKey</value>
      </list>
    </property>
    <property name="hasher" ref="hasher"/>
    <property name="debug" value="false"/>
  </bean>

  <bean id="dispatcher" class="com.yahoo.s4.dispatcher.Dispatcher" init-method="init">
    <property name="partitioners">
      <list>
        <ref bean="topicSeenPartitioner"/>
        <ref bean="aggregatedTopicSeenPartitioner"/>
      </list>
    </property>
    <property name="eventEmitter" ref="commLayerEmitter"/>
    <property name="loggerName" value="s4"/>
  </bean>

**Notes**
  * ``topicSeenPartitioner`` partitions the stream ``TopicSeen`` on the key ``topic``
  * ``aggregatedTopicSeenPartitioner`` partitions the stream ``AggregatedTopicSeen`` on the key ``reportKey``
  * ``dispatcher`` uses these partitioners to emit events accordingly
  
Build and run
-------------

This assumes you have built and setup S4 in ``${IMAGE_DIR}`` as described in :doc:`/tutorials/getting_started`

Set ``${APPNAME}`` to ``twittertopiccount_scala`` or ``twittertopiccount`` for Scala and Java versions respectively. 

Build
^^^^^

.. code-block:: bash

  cd ${SOURCE_DIR}
  git clone https://github.com/s4/examples.git
  cd examples/${APPNAME}
  mvn assembly:assembly install

Run
^^^

.. code-block:: bash

  cd ${IMAGE_DIR}/s4_apps
  tar xvzf ${SOURCE_DIR}/examples/${APPNAME}/target/${APPNAME}-*.jar
  cd ${IMAGE_DIR}/bin
  ./s4_start &
  ./run_adapter.sh -x -u ../s4_apps/${APPNAME}/lib/*.jar \
   -d ../s4_apps/${APPNAME}/adapter_conf.xml &

Output will be produced in :file:`/tmp/top_n_hashtags`
